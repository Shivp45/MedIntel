import streamlit as st
import os
from pathlib import Path
from backend.rag_pipeline import MedicalRAGPipeline

# Page config
st.set_page_config(
    page_title="Medical Research Assistant",
    page_icon="ğŸ¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        padding: 1rem 0;
    }
    .source-box {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border-left: 5px solid #ffc107;
        padding: 1rem;
        margin: 1rem 0;
    }
    .stButton>button {
        width: 100%;
        background-color: #1f77b4;
        color: white;
    }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []

if "pipeline" not in st.session_state:
    with st.spinner("ğŸ”§ Initializing Medical RAG System..."):
        st.session_state.pipeline = MedicalRAGPipeline()

# Header
st.markdown('<h1 class="main-header">ğŸ¥ Medical Research Assistant for Doctors</h1>', unsafe_allow_html=True)
st.markdown("---")

# Sidebar
with st.sidebar:
    st.header("âš™ï¸ System Information")
    
    # System health check
    health = st.session_state.pipeline.check_system_health()
    
    st.subheader("ğŸ“Š Status")
    st.write(f"Vector Store: {'âœ… Ready' if health['vectorstore'] else 'âŒ Not Found'}")
    st.write(f"Groq API: {'âœ… Configured' if health['groq_api'] else 'âŒ Missing Key'}")
    st.write(f"OpenAI API: {'âœ… Configured' if health['openai_api'] else 'âŒ Missing Key'}")
    
    st.markdown("---")
    
    st.subheader("â„¹ï¸ About")
    st.info(
        """
        This AI assistant helps doctors find information from medical literature.
        
        **Features:**
        - ğŸ“š Searches through ingested medical PDFs
        - ğŸ¯ Retrieves top 5 relevant sources
        - ğŸ¤– Powered by Llama 3.1-8B (Groq) with GPT-4o-mini fallback
        - âš ï¸ Highlights drug warnings and interactions
        """
    )
    
    st.markdown("---")
    
    if st.button("ğŸ—‘ï¸ Clear Chat History"):
        st.session_state.messages = []
        st.rerun()
    
    st.markdown("---")
    st.caption("ğŸ’¡ Ask evidence-based clinical questions")

# Main chat interface
st.subheader("ğŸ’¬ Chat with Medical Literature")

# Display chat messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        
        # Show sources if available
        if message["role"] == "assistant" and "sources" in message:
            with st.expander("ğŸ“š View Sources"):
                for i, source in enumerate(message["sources"], 1):
                    st.markdown(f"""
                    <div class="source-box">
                        <strong>Source {i}:</strong> {source['metadata'].get('source', 'Unknown')}<br>
                        <strong>Relevance Score:</strong> {source['similarity_score']:.4f}<br>
                        <strong>Preview:</strong> {source['text'][:200]}...
                    </div>
                    """, unsafe_allow_html=True)
            
            if "llm_used" in message:
                st.caption(f"ğŸ¤– Generated by: {message['llm_used']}")

# Chat input
if prompt := st.chat_input("Ask a medical question (e.g., 'What are the side effects of aspirin?')"):
    
    # Add user message
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Generate response
    with st.chat_message("assistant"):
        with st.spinner("ğŸ” Searching medical literature and generating answer..."):
            answer, context, llm_used = st.session_state.pipeline.generate_answer(prompt)
        
        st.markdown(answer)
        
        # Check for drug warnings
        warning_keywords = ["warning", "caution", "contraindication", "adverse", "side effect", "interaction"]
        if any(keyword in answer.lower() for keyword in warning_keywords):
            st.markdown("""
            <div class="warning-box">
                âš ï¸ <strong>Important:</strong> This response contains safety information. Please review carefully.
            </div>
            """, unsafe_allow_html=True)
        
        # Show sources
        if context:
            with st.expander("ğŸ“š View Sources", expanded=False):
                for i, source in enumerate(context, 1):
                    st.markdown(f"""
                    <div class="source-box">
                        <strong>Source {i}:</strong> {source['metadata'].get('source', 'Unknown')}<br>
                        <strong>Relevance Score:</strong> {source['similarity_score']:.4f}<br>
                        <strong>Preview:</strong> {source['text'][:200]}...
                    </div>
                    """, unsafe_allow_html=True)
        
        st.caption(f"ğŸ¤– Generated by: {llm_used}")
    
    # Save assistant message
    st.session_state.messages.append({
        "role": "assistant",
        "content": answer,
        "sources": context,
        "llm_used": llm_used
    })

# Footer
st.markdown("---")
st.caption("âš•ï¸ Medical Research Assistant | Built with RAG + Llama 3.1-8B + ChromaDB")
st.caption("âš ï¸ This tool is for research purposes. Always verify critical medical information.")